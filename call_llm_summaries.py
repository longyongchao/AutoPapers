import os
import re
from typing import Optional
import ollama

summarizes_paper = """
You are an experienced scientist. 
Your task is to summarize a paper in the field of deep learning. 
Please respond in clear, concise, and easy-to-understand language. 
Here are my specific requirements:

* The core topic of the paper: Summarize the theme or research question of the paper in one sentence.
* Main contributions: What problems does the paper solve? What new methods or insights does it propose?
* Core methods: Describe the main technical methods or algorithms proposed in the paper using simple language.
* Conclusion: Summarize the overall significance or value of this paper in one sentence.

Here is the full content of the paper:

{paper_partial_content}
"""

# å®šä¹‰è°ƒç”¨ Ollama API çš„å‡½æ•°
def call_llm(prompt: str, model: str = 'qwen2.5:72b-32k') -> Optional[str]:
    """
    è°ƒç”¨ Ollama API ç”Ÿæˆè¯­è¨€æ¨¡å‹çš„å“åº”ã€‚

    Parameters:
        prompt (str): æç¤ºè¯ï¼Œä¼ é€’ç»™è¯­è¨€æ¨¡å‹ã€‚
        model (str): ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º 'qwen2.5:72b-32k'ã€‚

    Returns:
        Optional[str]: æ¨¡å‹ç”Ÿæˆçš„å“åº”å†…å®¹ï¼Œå¦‚æœè°ƒç”¨å¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    try:
        # è°ƒç”¨ Ollama API
        result = ollama.chat(
            model=model,
            messages=[{"role": "user", "content": prompt}],
        )
        response: str = result['message']['content']
        return response
    except Exception as e:
        print(f"Error in LLM call: {e}")
        return None


def extract_abstract(md_content: str) -> Optional[str]:
    """
    ä» Markdown æ–‡ä»¶å†…å®¹ä¸­æå– `# Abstract` éƒ¨åˆ†çš„å†…å®¹ã€‚

    Parameters:
        md_content (str): Markdown æ–‡ä»¶çš„å†…å®¹ã€‚

    Returns:
        Optional[str]: `# Abstract` éƒ¨åˆ†çš„å†…å®¹ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› Noneã€‚
    """
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… `# Abstract` å’Œå…¶åçš„å†…å®¹ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜ï¼ˆå¦‚ `# 1 INTRODUCTION`ï¼‰
    match = re.search(r'#\s*Abstract\s*(.*?)\n(?=#|\Z)', md_content, re.IGNORECASE | re.DOTALL)
    if match:
        # æå– Abstract éƒ¨åˆ†çš„å†…å®¹ï¼Œå»æ‰é¦–å°¾ç©ºç™½
        return match.group(1).strip()
    else:
        return None


def preprocess_markdown_content(md_content: str) -> str:
    """
    é¢„å¤„ç† Markdown æ–‡ä»¶å†…å®¹ï¼š
    1. æˆªå–å‰ä¸‰åˆ†ä¹‹ä¸€çš„å†…å®¹ã€‚
    2. ç§»é™¤å›¾ç‰‡é“¾æ¥ã€‚

    Parameters:
        md_content (str): åŸå§‹ Markdown æ–‡ä»¶å†…å®¹ã€‚

    Returns:
        str: é¢„å¤„ç†åçš„ Markdown å†…å®¹ã€‚
    """
    # ç§»é™¤å›¾ç‰‡é“¾æ¥ï¼ˆåŒ¹é… ![](...) æ ¼å¼ï¼‰
    md_content = re.sub(r'!\[.*?\]\(.*?\)', '', md_content)

    # æŒ‰è¡Œåˆ†å‰²æ–‡ä»¶ï¼Œæˆªå–å‰ä¸‰åˆ†ä¹‹ä¸€çš„å†…å®¹
    lines = md_content.splitlines()
    one_third_length = max(1, len(lines) // 3)  # è‡³å°‘ä¿ç•™ä¸€è¡Œ
    partial_content = "\n".join(lines[:one_third_length])

    return partial_content


def summarize_markdown_files(md_folder: str, output_folder: str, model: str = 'qwen2.5:72b-32k'):
    """
    éå†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ Markdown æ–‡ä»¶ï¼Œè°ƒç”¨ LLM å¯¹å…¶å†…å®¹è¿›è¡Œæ€»ç»“ï¼Œå¹¶ä¿å­˜æ€»ç»“ç»“æœã€‚

    Parameters:
        md_folder (str): åŒ…å« Markdown æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        output_folder (str): ä¿å­˜æ€»ç»“ç»“æœçš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        model (str): ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º 'qwen2.5:72b-32k'ã€‚

    Returns:
        None
    """
    # ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs(output_folder, exist_ok=True)

    # è·å–æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰ Markdown æ–‡ä»¶
    md_files = [f for f in os.listdir(md_folder) if f.endswith('.md')]
    print('count of md_files:', len(md_files))

    if not md_files:
        print("No Markdown files found in the specified folder.")
        return

    # éå†æ¯ä¸ª Markdown æ–‡ä»¶
    for idx, md_file in enumerate(md_files):
        md_path = os.path.join(md_folder, md_file)
        output_path = os.path.join(output_folder, md_file)

        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨å¯¹åº”çš„è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_path):
            print(f"ğŸ˜“ Output already exists for {md_file}, skipping...")
            continue

        try:
            # è¯»å– Markdown æ–‡ä»¶å†…å®¹
            with open(md_path, 'r', encoding='utf-8') as f:
                md_content = f.read()

            # æå– `# Abstract` éƒ¨åˆ†å†…å®¹
            abstract_content = extract_abstract(md_content)
            if not abstract_content:
                print(f"ğŸ˜“ No Abstract found in {md_file}. Skipping Abstract appending.")

            # é¢„å¤„ç† Markdown æ–‡ä»¶å†…å®¹
            partial_content = preprocess_markdown_content(md_content)

            # æ„é€ æç¤ºè¯
            prompt = summarizes_paper.format(paper_partial_content=partial_content)

            # è°ƒç”¨ LLM ç”Ÿæˆæ€»ç»“
            print(f"ğŸ”¥ Summarizing: {md_file}...")
            summary = call_llm(prompt, model=model)

            if summary:
                # ä¿å­˜æ€»ç»“ç»“æœ
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(md_file.split('.')[0])
                    f.write("\n\n")
                    f.write(summary)

                    # å¦‚æœæœ‰ Abstract å†…å®¹ï¼Œå°†å…¶è¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾
                    if abstract_content:
                        f.write("\n\n# Abstract\n")
                        f.write(abstract_content)

                print(f"âœ… [{idx}/{len(md_files)}] Summary saved to: {output_path}")
            else:
                print(f"âŒ Failed to summarize: {md_file}")

        except Exception as e:
            print(f"Error processing file {md_file}: {e}")

    print("Summarization completed for all files.")


if __name__ == "__main__":
    # ç¤ºä¾‹è·¯å¾„
    md_folder = "/data/lyc/papers/ICLR_2024/md"  # æ›¿æ¢ä¸º Markdown æ–‡ä»¶æ‰€åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„
    output_folder = "/data/lyc/papers/ICLR_2024/sum"  # æ›¿æ¢ä¸ºæ€»ç»“ç»“æœä¿å­˜çš„æ–‡ä»¶å¤¹è·¯å¾„
    model = "llama3.1:70b-32k"  # ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹

    summarize_markdown_files(md_folder, output_folder, model)
